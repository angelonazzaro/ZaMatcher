{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390d0355-557e-4687-82c2-e3ce9097d834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender distribution: \n",
      "N    33.4180\n",
      "M    33.3676\n",
      "F    33.2144\n",
      "Name: gender, dtype: float64\n",
      "Searching Gender distribution: \n",
      "F    20.0932\n",
      "M    20.0758\n",
      "A    19.9492\n",
      "N    19.9436\n",
      "B    19.9382\n",
      "Name: searching_gender, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# CONSTANTS SECTION\n",
    "# M: Male, F: Female, B: Bisexual, N : Non Binary, A: All\n",
    "GENDER_MALE, GENDER_FEMALE, GENDER_NON_BINARY, = \"M\", \"F\", \"N\"\n",
    "SEARCHING_GENDER = [\"M\", \"F\", \"B\", \"N\", \"A\"]\n",
    "MIN_AGE, MAX_AGE = 18, 50\n",
    "INTEREST_MIN_SIZE, INTEREST_MAX_SIZE = 3, 6\n",
    "DS_SIZE = 500_000\n",
    "\n",
    "faker = Faker()\n",
    "\n",
    "# load datasets \n",
    "# taken from https://simplemaps.com/data/us-cities\n",
    "cities_df = pd.read_csv(\"./us_cities.csv\")\n",
    "interests = pd.read_csv(\"./interests.csv\")['interest'].tolist()\n",
    "\n",
    "ds_list = []\n",
    "\n",
    "for i in range(DS_SIZE):\n",
    "    row = {}\n",
    "\n",
    "\n",
    "    choice = random.randrange(1, 4)\n",
    "\n",
    "    if choice == 1:\n",
    "        row[\"name\"] = faker.first_name_male()\n",
    "        row[\"surname\"] = faker.last_name_male()\n",
    "        row[\"gender\"] = GENDER_MALE\n",
    "    elif choice == 2:\n",
    "        row[\"name\"] = faker.first_name_female()\n",
    "        row[\"surname\"] = faker.last_name_female()\n",
    "\n",
    "        row[\"gender\"] = GENDER_FEMALE\n",
    "    else:\n",
    "        row[\"name\"] = faker.first_name_nonbinary()\n",
    "        row[\"surname\"] = faker.last_name_nonbinary()\n",
    "        row[\"gender\"] = GENDER_NON_BINARY\n",
    "\n",
    "    row[\"searching_gender\"] = random.choice(SEARCHING_GENDER)\n",
    "    row[\"age\"] = random.randrange(MIN_AGE, MAX_AGE)\n",
    "    row_interests_size = random.randrange(INTEREST_MIN_SIZE, INTEREST_MAX_SIZE)\n",
    "\n",
    "    row['interests'] = ', '.join(random.sample(interests, row_interests_size))\n",
    "    cities_random_idx = random.randrange(cities_df.index.start, cities_df.index.stop)\n",
    "    row['latitude'] = cities_df['lat'][cities_random_idx]\n",
    "    row['longitude'] = cities_df['lng'][cities_random_idx]\n",
    "\n",
    "    ds_list.append(row)\n",
    "\n",
    "random.shuffle(ds_list)\n",
    "df = pd.DataFrame(ds_list)\n",
    "\n",
    "print(f\"Gender distribution: \\n{df['gender'].value_counts(normalize=True) * 100}\")\n",
    "print(f\"Searching Gender distribution: \\n{df['searching_gender'].value_counts(normalize=True) * 100}\")\n",
    "\n",
    "df.to_csv('dataset.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francesco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array(['Acting', 'Advertising', 'Air hockey', 'American football', 'Art',\n       'Art history', 'Astronomy', 'Astrophysics', 'Badminton', 'Baking',\n       'Ballet', 'Ballroom dancing', 'Bar tending', 'Baseball',\n       'Basketball', 'Biking', 'Billiards', 'Blacksmithing',\n       'Board games', 'Boating', 'Bouldering', 'Bowling', 'Boxing',\n       'Calligraphy', 'Card games', 'Carpentry', 'Ceramics',\n       'Choreography', 'Computer programming', 'Cooking', 'Cybersecurity',\n       'Cycling', 'DJing', 'Dancing', 'Darts', 'Data analysis', 'Diving',\n       'Drawing', 'Equestrian', 'Escape rooms', 'Ethical hacking',\n       'Fashion design', 'Field hockey', 'Filmmaking', 'Filmography',\n       'Financial analysis', 'Fishing', 'Fitness', 'Floristry',\n       'Food criticism', 'Food styling', 'Football', 'Gaming',\n       'Gardening', 'Geocaching', 'Glassblowing', 'Golf', 'Guitar',\n       'Gymnastics', 'Hang gliding', 'Hiking', 'Horseback riding',\n       'Hunting', 'Ice skating', 'Improv', 'Interests', 'Interior design',\n       'Investment banking', 'Jazz', 'Jogging', 'Journalism', 'Judo',\n       'Jujitsu', 'Karate', 'Kayaking', 'Kickboxing', 'Kiteboarding',\n       'Knitting', 'Lacrosse', 'Landscaping', 'Letterboxing',\n       'Literature', 'Marathons', 'Marketing', 'Martial arts',\n       'Mathematics', 'Meditation', 'Mixology', 'Mobile app development',\n       'Mountain biking', 'Movies', 'Muay Thai', 'Music',\n       'Music production', 'Nature', 'Nature Photography', 'Orienteering',\n       'Painting', 'Paragliding', 'Photography', 'Physics', 'Pilates',\n       'Pinball', 'Poetry', 'Polo', 'Pool', 'Pottery', 'Public relations',\n       'Puzzle solving', 'Rappelling', 'Reading', 'Road cycling',\n       'Rock Climbing', 'Rock climbing', 'Roller hockey', 'Rugby',\n       'Running', 'Sailing', 'Salsa', 'Sculpting', 'Self defense',\n       'Sewing', 'Shuffleboard', 'Singing', 'Skateboarding', 'Sketching',\n       'Skiing', 'Skydiving', 'Snowboarding', 'Soccer', 'Squash',\n       'Stand-up comedy', 'Stock trading', 'Surfing', 'Swimming',\n       'Synchronized swimming', 'Table tennis', 'Teaching', 'Tennis',\n       'Theater', 'Theatre', 'Travel', 'Treasure hunting', 'Triathlons',\n       'Video editing', 'Video games', 'Volleyball', 'Water polo',\n       'Watercolor', 'Web design', 'Weightlifting', 'Windsurfing',\n       'Wine tasting', 'Woodworking', 'Wrestling', 'Writing', 'Yachting',\n       'Yoga'], dtype=object)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re #mi serve per usare textsplit\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer #lib per vect\n",
    "\n",
    "vect = CountVectorizer(tokenizer = lambda text: re.split(\", \", text), lowercase = False)\n",
    "label = vect.fit_transform(df['interests'])\n",
    "vect.get_feature_names_out()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "             name   surname gender searching_gender  age  latitude  longitude  \\\n0         Suzanne       Fox      N                N   32   36.5367   -95.9264   \n1         Matthew   Coleman      M                B   45   39.2920   -75.0097   \n2       Elizabeth     Jones      N                A   39   41.9170  -104.2955   \n3           Jenna     Perez      N                B   35   44.1810   -94.0391   \n4         Michael     Smith      M                N   23   32.8560  -116.9040   \n...           ...       ...    ...              ...  ...       ...        ...   \n499995      Laura     Smith      F                B   46   43.9987   -95.8575   \n499996     Alicia      Gray      F                N   19   40.7974   -76.4284   \n499997     Martin  Anderson      M                M   31   38.5116   -76.6797   \n499998    Lindsay      Hunt      F                N   21   42.0208   -95.9662   \n499999      Ruben   Marquez      M                B   30   45.3864  -122.5934   \n\n        Acting  Advertising  Air hockey  ...  Watercolor  Web design  \\\n0            0            0           0  ...           0           0   \n1            0            0           0  ...           0           0   \n2            0            0           1  ...           0           0   \n3            0            0           0  ...           0           0   \n4            0            0           0  ...           0           0   \n...        ...          ...         ...  ...         ...         ...   \n499995       0            0           0  ...           0           0   \n499996       0            0           0  ...           0           0   \n499997       0            0           0  ...           0           0   \n499998       0            0           0  ...           0           0   \n499999       0            0           0  ...           0           0   \n\n        Weightlifting  Windsurfing  Wine tasting  Woodworking  Wrestling  \\\n0                   0            0             0            0          0   \n1                   0            0             0            0          0   \n2                   0            0             0            0          0   \n3                   0            0             0            0          0   \n4                   0            0             0            0          0   \n...               ...          ...           ...          ...        ...   \n499995              0            0             0            0          0   \n499996              0            0             0            0          0   \n499997              0            0             0            0          0   \n499998              1            0             0            0          0   \n499999              0            0             0            0          0   \n\n        Writing  Yachting  Yoga  \n0             0         0     0  \n1             0         0     0  \n2             0         0     0  \n3             0         0     0  \n4             0         0     0  \n...         ...       ...   ...  \n499995        0         0     0  \n499996        0         0     0  \n499997        0         0     0  \n499998        0         0     0  \n499999        0         0     0  \n\n[500000 rows x 165 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>surname</th>\n      <th>gender</th>\n      <th>searching_gender</th>\n      <th>age</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>Acting</th>\n      <th>Advertising</th>\n      <th>Air hockey</th>\n      <th>...</th>\n      <th>Watercolor</th>\n      <th>Web design</th>\n      <th>Weightlifting</th>\n      <th>Windsurfing</th>\n      <th>Wine tasting</th>\n      <th>Woodworking</th>\n      <th>Wrestling</th>\n      <th>Writing</th>\n      <th>Yachting</th>\n      <th>Yoga</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Suzanne</td>\n      <td>Fox</td>\n      <td>N</td>\n      <td>N</td>\n      <td>32</td>\n      <td>36.5367</td>\n      <td>-95.9264</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Matthew</td>\n      <td>Coleman</td>\n      <td>M</td>\n      <td>B</td>\n      <td>45</td>\n      <td>39.2920</td>\n      <td>-75.0097</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Elizabeth</td>\n      <td>Jones</td>\n      <td>N</td>\n      <td>A</td>\n      <td>39</td>\n      <td>41.9170</td>\n      <td>-104.2955</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jenna</td>\n      <td>Perez</td>\n      <td>N</td>\n      <td>B</td>\n      <td>35</td>\n      <td>44.1810</td>\n      <td>-94.0391</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Michael</td>\n      <td>Smith</td>\n      <td>M</td>\n      <td>N</td>\n      <td>23</td>\n      <td>32.8560</td>\n      <td>-116.9040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>499995</th>\n      <td>Laura</td>\n      <td>Smith</td>\n      <td>F</td>\n      <td>B</td>\n      <td>46</td>\n      <td>43.9987</td>\n      <td>-95.8575</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>499996</th>\n      <td>Alicia</td>\n      <td>Gray</td>\n      <td>F</td>\n      <td>N</td>\n      <td>19</td>\n      <td>40.7974</td>\n      <td>-76.4284</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>499997</th>\n      <td>Martin</td>\n      <td>Anderson</td>\n      <td>M</td>\n      <td>M</td>\n      <td>31</td>\n      <td>38.5116</td>\n      <td>-76.6797</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>499998</th>\n      <td>Lindsay</td>\n      <td>Hunt</td>\n      <td>F</td>\n      <td>N</td>\n      <td>21</td>\n      <td>42.0208</td>\n      <td>-95.9662</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>499999</th>\n      <td>Ruben</td>\n      <td>Marquez</td>\n      <td>M</td>\n      <td>B</td>\n      <td>30</td>\n      <td>45.3864</td>\n      <td>-122.5934</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>500000 rows Ã— 165 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interests = pd.DataFrame(label.toarray(), columns = vect.get_feature_names_out())\n",
    "df = pd.concat([df, df_interests], axis = 1)\n",
    "df.drop(\"interests\", axis = 1, inplace = True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
